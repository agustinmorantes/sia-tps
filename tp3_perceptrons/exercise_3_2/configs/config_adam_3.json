{
    "name": "base_adam",
    "layer_sizes": [35, 15, 1],
    "activation": "tanh",
    "eta": 0.01,
    "optimizer": "adam",
    "batch_size": 1,
    "epochs": 100,
    "epsilon": 1e-8,
    "alpha": 0.9,
    "seed": 123
}
